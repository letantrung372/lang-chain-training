{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "- WSL\n",
    "- Miniconda3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment\n",
    "- Create conda env `conda create langchain python=3.11`\n",
    "- Set the \"langchain\" env that has been just created as the running env in VS code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install langchain and openai package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set value of `OPENAI_API_KEY` that you get from the training team in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "\n",
    "os.environ[\"AZURE_AI_SEARCH_SERVICE_NAME\"] = os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\")\n",
    "os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"] = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\")\n",
    "os.environ[\"AZURE_AI_SEARCH_API_KEY\"] = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = f\"https://{os.getenv('AZURE_OPENAI_SERVICE')}.openai.azure.com\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overviews\n",
    "The BonBon FAQ.pdf file contains frequently asked questions and answers for customer support scenario. The topics are around IT related issue troubleshooting such as networking, software, hardware. You are requested to provide a solution to build a chat bot capable of answering the user questions with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Document Indexing (mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The content of BonBon FAQ.pdf should be indexed to the local Chroma vector DB from where the chatbot can lookup the appropriate information to answer questions.\n",
    "- Should use some embedding model such as Azure Open AI text-embedding-3-small to create vectors, feel free to use any other open source embedding model if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 63\n",
      "Index already exists.\n",
      "Uploading documents...\n",
      "Upload result: [<azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b785217d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522890>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520710>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522950>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78523790>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522cd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78521550>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522410>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522550>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78523ed0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78521890>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78523890>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78521d50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78521710>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78521390>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b785223d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b785238d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78523b90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520650>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520150>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520550>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522450>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78522490>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78523a10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520f50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b78520090>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fc850>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fde90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782ff490>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782ff450>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782ff3d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782ffb10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fe590>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fe4d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fdd10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782ff690>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fd490>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fd850>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fcf50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fdb10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fcfd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fd510>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fe690>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fe790>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fde10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fe8d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fd2d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fd310>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b782fc650>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855ca90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855c1d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855c210>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855f350>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855cb50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855e110>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855ef90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855dbd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855edd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855c510>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855c350>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855ed10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855df50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x759b7855c250>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import fitz\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SimpleField, SearchField, SearchFieldDataType,\n",
    "    SearchableField, VectorSearch, HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile, VectorSearchAlgorithmKind, HnswParameters\n",
    ")\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# ===== Load ENV =====\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "AZURE_SEARCH_INDEX = \"gptkbindex-pdf\"\n",
    "\n",
    "# ===== Load PDF file =====\n",
    "def read_pdf_by_page(file_path):\n",
    "    pages = []\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text = page.get_text()\n",
    "            pages.append(text)\n",
    "    return pages\n",
    "\n",
    "pages = read_pdf_by_page(\"./data/BonBon FAQ.pdf\")\n",
    "\n",
    "# ===== Split page into semantic chunks =====\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "sourcefile_name = \"bonbon_faq.pdf\"\n",
    "chunks_with_metadata = []\n",
    "for page_number, page_text in enumerate(pages, start=1):\n",
    "    sub_chunks = splitter.split_text(page_text)\n",
    "    for chunk in sub_chunks:\n",
    "        chunks_with_metadata.append({\n",
    "            \"content\": chunk,\n",
    "            \"page\": page_number,\n",
    "            \"sourcefile\": sourcefile_name\n",
    "        })\n",
    "\n",
    "print(f\"Total chunks: {len(chunks_with_metadata)}\")\n",
    "\n",
    "# ===== Setup Azure OpenAI client =====\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    ")\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = openai_client.embeddings.create(\n",
    "        model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# ===== Generate embeddings & prepare documents =====\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunks_with_metadata):\n",
    "    embedding = get_embedding(chunk[\"content\"])\n",
    "    documents.append({\n",
    "        \"id\": str(i),\n",
    "        \"content\": chunk[\"content\"],\n",
    "        \"embedding\": embedding,\n",
    "        \"sourcefile\": chunk[\"sourcefile\"],\n",
    "        \"page\": chunk[\"page\"]\n",
    "    })\n",
    "\n",
    "# ===== Create index (once) =====\n",
    "search_cred = AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=search_cred)\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_INDEX,\n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"sourcefile\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SimpleField(name=\"page\", type=SearchFieldDataType.Int32, filterable=True),\n",
    "        SearchField(\n",
    "            name=\"embedding\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=1536,\n",
    "            vector_search_profile_name=\"embedding_profile\"\n",
    "        )\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"hnsw_config\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(metric=\"cosine\")\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"embedding_profile\",\n",
    "                algorithm_configuration_name=\"hnsw_config\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tạo index nếu chưa tồn tại\n",
    "try:\n",
    "    index_client.get_index(AZURE_SEARCH_INDEX)\n",
    "    print(\"Index already exists.\")\n",
    "except:\n",
    "    print(\"Creating new index...\")\n",
    "    index_client.create_index(index)\n",
    "\n",
    "# ===== Upload documents =====\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=search_cred\n",
    ")\n",
    "\n",
    "print(\"Uploading documents...\")\n",
    "upload_result = search_client.upload_documents(documents=documents)\n",
    "print(f\"Upload result: {upload_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Search Results ===\n",
      "[Page 9] Score: 0.7684\n",
      "2) Know the Shared Drive Path: \n",
      "• \n",
      "You should have the network path or UNC (Universal Naming Convention) of the shared \n",
      "drive. It typically looks like this: \\\\computername\\sharename or \\\\IP_address\\sh\n",
      "---\n",
      "[Page 9] Score: 0.7612\n",
      "5) In File Explorer, go to \"This PC.\" \n",
      "• \n",
      "Click on \"Computer\" in the top menu and select \"Map network drive.\" \n",
      "• \n",
      "Choose a drive letter and enter the UNC path (e.g., \\\\server\\share). \n",
      "• \n",
      "Check the box\n",
      "---\n",
      "[Page 9] Score: 0.7261\n",
      "• \n",
      "If you haven't mapped the drive, you can directly access it by entering the UNC path in the \n",
      "address bar of File Explorer and pressing Enter. \n",
      " \n",
      "7) Provide Credentials (if required): \n",
      "• \n",
      "If the sha\n",
      "---\n",
      "[Page 10] Score: 0.7168\n",
      "8) Access Files and Folders: \n",
      "• \n",
      "Once you're connected to the shared drive, you can browse, open, and manage files and \n",
      "folders just like you would on your local drive. \n",
      "Please note that the exact ste\n",
      "---\n",
      "[Page 9] Score: 0.6889\n",
      "• \n",
      "If all else fails, uninstall the printer software from your laptop and reinstall it. Visit the \n",
      "printer manufacturer's website and download the latest software for your printer model. Follow \n",
      "the p\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ===== Search thử bằng vector =====\n",
    "search_query = \"How do I access shared network drives?\"\n",
    "search_vector = get_embedding(search_query)\n",
    "\n",
    "print(\"\\n=== Search Results ===\")\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    top=5,\n",
    "    vector_queries=[\n",
    "        VectorizedQuery(\n",
    "            vector=search_vector,\n",
    "            k_nearest_neighbors=5,\n",
    "            fields=\"embedding\"\n",
    "        )\n",
    "    ],\n",
    "    filter=f\"sourcefile eq '{sourcefile_name}'\"\n",
    ")\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"[Page {doc['page']}] Score: {doc['@search.score']:.4f}\")\n",
    "    print(doc[\"content\"][:200])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Building Chatbot (mandatory)\n",
    "- You are requested to build a chatbot solution for customer support scenario using Conversational ReAct agent supported in LangChain\n",
    "- The chatbot is able to support user to answer FAQs in the sample BonBon FAQ.pdf file.\n",
    "- The chatbot should use Azure Open AI GPT-4o LLM as the reasoning engine.\n",
    "- The chatbot should be context aware, meaning that it should be able to chat with users in the conversation manner.\n",
    "- The agent is equipped the following tools:\n",
    "  - Internet Search: Help the chatbot automatically find out more about something using Duck Duck Go internet search\n",
    "  - Knowledge Base Search: Help the chatbot to lookup information in the private knowledge base\n",
    "- In case user asks for information related to topics in the BonBon FAQ.pdf file such as internet connection, printer, malware issues the chatbot must use the private knowledge base, otherwise it should search on the internet to answer the question.\n",
    "- In the answer of chatbot, it should mention the source file and the page that the answer belongs to, for example the answer should mention \"BonBon FQA.pdf (page 2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge base tool\n",
    "from langchain.tools import Tool\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools import Tool\n",
    "from langchain.retrievers.azure_ai_search import AzureAISearchRetriever\n",
    "\n",
    "def get_ddg_tool():\n",
    "    return DuckDuckGoSearchRun(name=\"DuckDuckGoSearch\", func=\"search_web\", description=(\n",
    "        \"Use this tool when the question is general or not related to BonBon company FAQs. \"\n",
    "        \"This includes general internet knowledge, latest updates, or topics not covered by internal support.\"\n",
    "    ))\n",
    "\n",
    "def get_kb_tool():\n",
    "    retriever = AzureAISearchRetriever(\n",
    "        content_key=\"content\", top_k=1, index_name=\"gptkbindex-pdf\"\n",
    "    )\n",
    "\n",
    "    def _search_kb(query: str) -> str:\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        return \"\\n\".join([\n",
    "            f\"{doc.page_content}\\nSource: {doc.metadata.get('sourcefile', 'Unknown')} (page {doc.metadata.get('page', '?')})\"\n",
    "            for doc in docs\n",
    "        ])\n",
    "\n",
    "    return Tool(\n",
    "        name=\"KnowledgeBaseSearch\",\n",
    "        func=_search_kb,\n",
    "        description=\"Use for answering BonBon FAQ-related topics like internet, printer, malware, VPN, etc.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://sd1096-langchain-training.openai.azure.com to https://sd1096-langchain-training.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://sd1096-langchain-training.openai.azure.com to https://sd1096-langchain-training.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to BonBon Support Chatbot!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes  \n",
      "Action: DuckDuckGoSearch  \n",
      "Action Input: Tổng thống Mỹ hiện tại là ai?  \n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mJan 22, 2025 · Donald Trump (tên đầy đủ: Donald John Trump) là tỷ phú, chính trị gia và Tổng thống thứ 45 của Hợp Chúng Quốc Hoa Kỳ nhiệm kỳ 2017 - 2021. Hiện tại, ông đang là Tổng … Nov 6, 2024 · VOV.VN - Vào rạng sáng ngày 6/11, truyền thông Mỹ, cụ thể là Fox News đã dự báo ứng viên đảng Cộng hòa Donald Trump chiến thắng và trở thành Tổng thống thứ 47 của … Nov 6, 2024 · Cựu Tổng thống Donald Trump và Phó Tổng thống Kamala Harris có những điểm mạnh riêng để trở thành Tổng thống thứ 47 của nước Mỹ. Jul 19, 2024 · Tổng thống Mỹ hiện nay là ông Joe Biden. Ông nhậm chức vào ngày 20 tháng 1 năm 2021, sau khi giành chiến thắng trong cuộc bầu cử tổng thống Mỹ năm 2020 trước đối thủ … Nov 6, 2024 · Nhiệm kỳ duy nhất của Tổng thống Joe Biden thể hiện tính tham vọng và tiến bộ vượt quá những gì từng được dự đoán.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:274: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mDo I need to use a tool? No  \n",
      "AI: Tổng thống Mỹ hiện tại là Joe Biden. Ông nhậm chức vào ngày 20 tháng 1 năm 2021 sau khi giành chiến thắng trong cuộc bầu cử tổng thống Mỹ năm 2020.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Tổng thống Mỹ hiện tại là Joe Biden. Ông nhậm chức vào ngày 20 tháng 1 năm 2021 sau khi giành chiến thắng trong cuộc bầu cử tổng thống Mỹ năm 2020.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:274: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes  \n",
      "Action: KnowledgeBaseSearch  \n",
      "Action Input: remove malware from your computer  \n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mantivirus program. \n",
      "3)  Remove the malware: \n",
      "• \n",
      "Follow the instructions provided by your antivirus software to remove the detected \n",
      "malware. This often involves quarantining or deleting infected files and cleaning your \n",
      "system. \n",
      "4)  Update your operating system and software: \n",
      "• \n",
      "Make sure your operating system and all installed software are up to date. Malware often \n",
      "takes advantage of vulnerabilities in outdated software. \n",
      " 5)  Change passwords: \n",
      "•\n",
      "Source: BonBon FAQ.pdf (page 10)\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lttrung372/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:274: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mDo I need to use a tool? No  \n",
      "AI: To remove malware from your computer, follow these steps:\n",
      "\n",
      "1. **Install and Run Antivirus Software**: If you don't already have an antivirus program installed, download and install a reputable one. Perform a full system scan to detect any malware.\n",
      "\n",
      "2. **Follow Antivirus Instructions**: After the scan, follow the instructions provided by the antivirus software to remove the detected malware. This might involve quarantining or deleting infected files and cleaning your system.\n",
      "\n",
      "3. **Update Your Software**: Ensure that your operating system and all installed software are up to date. Malware often exploits vulnerabilities in outdated software.\n",
      "\n",
      "4. **Change Passwords**: Once the malware is removed, change passwords for your important accounts, especially if you suspect the malware might have compromised sensitive information.\n",
      "\n",
      "5. **Enable Regular Scans and Updates**: Set your antivirus software to perform regular scans and keep it updated to prevent future infections.\n",
      "\n",
      "Let me know if you need further assistance!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: To remove malware from your computer, follow these steps:\n",
      "\n",
      "1. **Install and Run Antivirus Software**: If you don't already have an antivirus program installed, download and install a reputable one. Perform a full system scan to detect any malware.\n",
      "\n",
      "2. **Follow Antivirus Instructions**: After the scan, follow the instructions provided by the antivirus software to remove the detected malware. This might involve quarantining or deleting infected files and cleaning your system.\n",
      "\n",
      "3. **Update Your Software**: Ensure that your operating system and all installed software are up to date. Malware often exploits vulnerabilities in outdated software.\n",
      "\n",
      "4. **Change Passwords**: Once the malware is removed, change passwords for your important accounts, especially if you suspect the malware might have compromised sensitive information.\n",
      "\n",
      "5. **Enable Regular Scans and Updates**: Set your antivirus software to perform regular scans and keep it updated to prevent future infections.\n",
      "\n",
      "Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4o-deployment\",\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "\n",
    "tools = [get_ddg_tool(), get_kb_tool()]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to BonBon Support Chatbot!\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        response = agent_executor.invoke({\"input\": user_input})\n",
    "        print(\"Bot:\", response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Build a new assistant based on BonBon source code (optional)\n",
    "The objective\n",
    "- Run the code and index the sample BonBon FAQ.pdf file to Azure Cognitive Search\n",
    "- Explore the code and implement a new assistant that has the same behavior as above\n",
    "- Explore other features such as RBACs, features on admin portal\n",
    "\n",
    "Please contact the training team in case you need to get the source code of BonBon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
