{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "- WSL\n",
    "- Miniconda3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment\n",
    "- Create conda env `conda create langchain python=3.11`\n",
    "- Set the \"langchain\" env that has been just created as the running env in VS code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install langchain and openai package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set value of `OPENAI_API_KEY` that you get from the training team in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overviews\n",
    "The BonBon FAQ.pdf file contains frequently asked questions and answers for customer support scenario. The topics are around IT related issue troubleshooting such as networking, software, hardware. You are requested to provide a solution to build a chat bot capable of answering the user questions with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Document Indexing (mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The content of BonBon FAQ.pdf should be indexed to the local Chroma vector DB from where the chatbot can lookup the appropriate information to answer questions.\n",
    "- Should use some embedding model such as Azure Open AI text-embedding-3-small to create vectors, feel free to use any other open source embedding model if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 63\n",
      "Index already exists.\n",
      "Uploading documents...\n",
      "Upload result: [<azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f2174f750>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f2174c650>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f2174e6d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f2174cfd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f2156a9d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21568250>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217d81d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217d88d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217dbf90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217da250>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217d8390>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217dad10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217dba10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21686ed0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21686b10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213a7890>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213a4950>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f4dd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7fd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f4a10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f6710>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f4ad0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f6b50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f4610>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f5810>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7c50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f6410>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f4890>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7990>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7210>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7cd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f5dd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f71d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f215f7b90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21e9f650>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213fca50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213ffad0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213ffa50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213fcf90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213ffc50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213ffcd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217cfa50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217a9010>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217a8750>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217aa8d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217a8490>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217a81d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217a9590>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217aab90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217ab910>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f217ab690>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21396a90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f213971d0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21395a50>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21394790>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21394390>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21397710>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21396b90>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21395bd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21397bd0>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21397850>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21394150>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x7f0f21397350>]\n",
      "\n",
      "=== Search Results ===\n",
      "[Page 9] Score: 0.7684\n",
      "2) Know the Shared Drive Path: \n",
      "• \n",
      "You should have the network path or UNC (Universal Naming Convention) of the shared \n",
      "drive. It typically looks like this: \\\\computername\\sharename or \\\\IP_address\\sh\n",
      "---\n",
      "[Page 9] Score: 0.7612\n",
      "5) In File Explorer, go to \"This PC.\" \n",
      "• \n",
      "Click on \"Computer\" in the top menu and select \"Map network drive.\" \n",
      "• \n",
      "Choose a drive letter and enter the UNC path (e.g., \\\\server\\share). \n",
      "• \n",
      "Check the box\n",
      "---\n",
      "[Page 9] Score: 0.7261\n",
      "• \n",
      "If you haven't mapped the drive, you can directly access it by entering the UNC path in the \n",
      "address bar of File Explorer and pressing Enter. \n",
      " \n",
      "7) Provide Credentials (if required): \n",
      "• \n",
      "If the sha\n",
      "---\n",
      "[Page 10] Score: 0.7168\n",
      "8) Access Files and Folders: \n",
      "• \n",
      "Once you're connected to the shared drive, you can browse, open, and manage files and \n",
      "folders just like you would on your local drive. \n",
      "Please note that the exact ste\n",
      "---\n",
      "[Page 9] Score: 0.6889\n",
      "• \n",
      "If all else fails, uninstall the printer software from your laptop and reinstall it. Visit the \n",
      "printer manufacturer's website and download the latest software for your printer model. Follow \n",
      "the p\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import fitz\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SimpleField, SearchField, SearchFieldDataType,\n",
    "    SearchableField, VectorSearch, HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile, VectorSearchAlgorithmKind, HnswParameters\n",
    ")\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# ===== Load ENV =====\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "AZURE_SEARCH_INDEX = \"gptkbindex-pdf\"\n",
    "\n",
    "# ===== Load PDF file =====\n",
    "def read_pdf_by_page(file_path):\n",
    "    pages = []\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text = page.get_text()\n",
    "            pages.append(text)\n",
    "    return pages\n",
    "\n",
    "pages = read_pdf_by_page(\"./data/BonBon FAQ.pdf\")\n",
    "\n",
    "# ===== Split page into semantic chunks =====\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "sourcefile_name = \"bonbon_faq.pdf\"\n",
    "chunks_with_metadata = []\n",
    "for page_number, page_text in enumerate(pages, start=1):\n",
    "    sub_chunks = splitter.split_text(page_text)\n",
    "    for chunk in sub_chunks:\n",
    "        chunks_with_metadata.append({\n",
    "            \"content\": chunk,\n",
    "            \"page\": page_number,\n",
    "            \"sourcefile\": sourcefile_name\n",
    "        })\n",
    "\n",
    "print(f\"Total chunks: {len(chunks_with_metadata)}\")\n",
    "\n",
    "# ===== Setup Azure OpenAI client =====\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    ")\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = openai_client.embeddings.create(\n",
    "        model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# ===== Generate embeddings & prepare documents =====\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunks_with_metadata):\n",
    "    embedding = get_embedding(chunk[\"content\"])\n",
    "    documents.append({\n",
    "        \"id\": str(i),\n",
    "        \"content\": chunk[\"content\"],\n",
    "        \"embedding\": embedding,\n",
    "        \"sourcefile\": chunk[\"sourcefile\"],\n",
    "        \"page\": chunk[\"page\"]\n",
    "    })\n",
    "\n",
    "# ===== Create index (once) =====\n",
    "search_cred = AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=search_cred)\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_INDEX,\n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"sourcefile\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SimpleField(name=\"page\", type=SearchFieldDataType.Int32, filterable=True),\n",
    "        SearchField(\n",
    "            name=\"embedding\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=1536,\n",
    "            vector_search_profile_name=\"embedding_profile\"\n",
    "        )\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"hnsw_config\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(metric=\"cosine\")\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"embedding_profile\",\n",
    "                algorithm_configuration_name=\"hnsw_config\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tạo index nếu chưa tồn tại\n",
    "try:\n",
    "    index_client.get_index(AZURE_SEARCH_INDEX)\n",
    "    print(\"Index already exists.\")\n",
    "except:\n",
    "    print(\"Creating new index...\")\n",
    "    index_client.create_index(index)\n",
    "\n",
    "# ===== Upload documents =====\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=search_cred\n",
    ")\n",
    "\n",
    "print(\"Uploading documents...\")\n",
    "upload_result = search_client.upload_documents(documents=documents)\n",
    "print(f\"Upload result: {upload_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Search Results ===\n",
      "[Page 9] Score: 0.7684\n",
      "2) Know the Shared Drive Path: \n",
      "• \n",
      "You should have the network path or UNC (Universal Naming Convention) of the shared \n",
      "drive. It typically looks like this: \\\\computername\\sharename or \\\\IP_address\\sh\n",
      "---\n",
      "[Page 9] Score: 0.7612\n",
      "5) In File Explorer, go to \"This PC.\" \n",
      "• \n",
      "Click on \"Computer\" in the top menu and select \"Map network drive.\" \n",
      "• \n",
      "Choose a drive letter and enter the UNC path (e.g., \\\\server\\share). \n",
      "• \n",
      "Check the box\n",
      "---\n",
      "[Page 9] Score: 0.7261\n",
      "• \n",
      "If you haven't mapped the drive, you can directly access it by entering the UNC path in the \n",
      "address bar of File Explorer and pressing Enter. \n",
      " \n",
      "7) Provide Credentials (if required): \n",
      "• \n",
      "If the sha\n",
      "---\n",
      "[Page 10] Score: 0.7168\n",
      "8) Access Files and Folders: \n",
      "• \n",
      "Once you're connected to the shared drive, you can browse, open, and manage files and \n",
      "folders just like you would on your local drive. \n",
      "Please note that the exact ste\n",
      "---\n",
      "[Page 9] Score: 0.6889\n",
      "• \n",
      "If all else fails, uninstall the printer software from your laptop and reinstall it. Visit the \n",
      "printer manufacturer's website and download the latest software for your printer model. Follow \n",
      "the p\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ===== Search thử bằng vector =====\n",
    "search_query = \"How do I access shared network drives?\"\n",
    "search_vector = get_embedding(search_query)\n",
    "\n",
    "print(\"\\n=== Search Results ===\")\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    top=5,\n",
    "    vector_queries=[\n",
    "        VectorizedQuery(\n",
    "            vector=search_vector,\n",
    "            k_nearest_neighbors=5,\n",
    "            fields=\"embedding\"\n",
    "        )\n",
    "    ],\n",
    "    filter=f\"sourcefile eq '{sourcefile_name}'\"\n",
    ")\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"[Page {doc['page']}] Score: {doc['@search.score']:.4f}\")\n",
    "    print(doc[\"content\"][:200])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Building Chatbot (mandatory)\n",
    "- You are requested to build a chatbot solution for customer support scenario using Conversational ReAct agent supported in LangChain\n",
    "- The chatbot is able to support user to answer FAQs in the sample BonBon FAQ.pdf file.\n",
    "- The chatbot should use Azure Open AI GPT-4o LLM as the reasoning engine.\n",
    "- The chatbot should be context aware, meaning that it should be able to chat with users in the conversation manner.\n",
    "- The agent is equipped the following tools:\n",
    "  - Internet Search: Help the chatbot automatically find out more about something using Duck Duck Go internet search\n",
    "  - Knowledge Base Search: Help the chatbot to lookup information in the private knowledge base\n",
    "- In case user asks for information related to topics in the BonBon FAQ.pdf file such as internet connection, printer, malware issues the chatbot must use the private knowledge base, otherwise it should search on the internet to answer the question.\n",
    "- In the answer of chatbot, it should mention the source file and the page that the answer belongs to, for example the answer should mention \"BonBon FQA.pdf (page 2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     27\u001b[39m prompt = ChatPromptTemplate.from_messages(\n\u001b[32m     28\u001b[39m     [\n\u001b[32m     29\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     ]\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Construct the Tools agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m agent = \u001b[43mcreate_tool_calling_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Create an agent executor by passing in the agent and tools\u001b[39;00m\n\u001b[32m     43\u001b[39m agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain/agents/tool_calling_agent/base.py:99\u001b[39m, in \u001b[36mcreate_tool_calling_agent\u001b[39m\u001b[34m(llm, tools, prompt, message_formatter)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(llm, \u001b[33m\"\u001b[39m\u001b[33mbind_tools\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis function requires a .bind_tools method be implemented on the LLM.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m llm_with_tools = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m agent = (\n\u001b[32m    102\u001b[39m     RunnablePassthrough.assign(\n\u001b[32m    103\u001b[39m         agent_scratchpad=\u001b[38;5;28;01mlambda\u001b[39;00m x: message_formatter(x[\u001b[33m\"\u001b[39m\u001b[33mintermediate_steps\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m     | ToolsAgentOutputParser()\n\u001b[32m    108\u001b[39m )\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1341\u001b[39m, in \u001b[36mBaseChatModel.bind_tools\u001b[39m\u001b[34m(self, tools, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_tools\u001b[39m(\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1325\u001b[39m     tools: Sequence[\n\u001b[32m   (...)\u001b[39m\u001b[32m   1330\u001b[39m     **kwargs: Any,\n\u001b[32m   1331\u001b[39m ) -> Runnable[LanguageModelInput, BaseMessage]:\n\u001b[32m   1332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Bind tools to the model.\u001b[39;00m\n\u001b[32m   1333\u001b[39m \n\u001b[32m   1334\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1339\u001b[39m \u001b[33;03m        A Runnable that returns a message.\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# from llm import get_langchain_azure_openai_llm\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "# from langchain.chains import LLMathChain\n",
    "from langchain.tools import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# llm_math = LLMathChain.from_llm(llm)\n",
    "\n",
    "tools = [\n",
    "    DuckDuckGoSearchRun(description=\"use this tool to search for information on internet\"),\n",
    "    # Tool(\n",
    "    #     name=\"calculator\",\n",
    "    #     func=llm_math.run,\n",
    "    #     description=\"use this tool for math calculating\"\n",
    "    # )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "while True:\n",
    "    question = input(\"Human: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    \n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    print(f\"AI: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Build a new assistant based on BonBon source code (optional)\n",
    "The objective\n",
    "- Run the code and index the sample BonBon FAQ.pdf file to Azure Cognitive Search\n",
    "- Explore the code and implement a new assistant that has the same behavior as above\n",
    "- Explore other features such as RBACs, features on admin portal\n",
    "\n",
    "Please contact the training team in case you need to get the source code of BonBon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
